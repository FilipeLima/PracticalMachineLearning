---
title: "Qualitative analysis of weight lifting exercises"
author: "Filipe Lima"
date: "24/10/2020"
output: md_document
---

## Background

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: [HAR Project](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).


## Data cleaning

First we will find the most relevant variables in the [Training data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) for the project. We chose the ones that have the results for roll, yaw, pitch, gyros, accel and magnet for belt, forearm, arm and dumbell, and of course, the classe variable. We based our choice using the description of the variables in this [article](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf) by Velloso *et al*. Then we will create a new dataset using those variables and classe as a factor.

```{r, warning=FALSE}
library(caret)
library(parallel) 
library(doParallel) #For parallel computing
WLEdataframe <- read.csv("pml-training.csv")
WLEdataframe$classe <- as.factor(WLEdataframe$classe)
#The index of the variables we want
Selection1 <- c(8:10,37:48,60:68,84:86,113:124,151:160)
WLEdataframe <- WLEdataframe[,Selection1]
```

The variables in this new dataframe are:

```{r}
names(WLEdataframe)
```

With this line of code we can confirm that there are no NA values in this new dataset.

```{r}
sum(is.na(WLEdataframe))
```



## Splitting and training

We split the dataset using 75% for training. We use cross validation as a method of train control and a 10-fold cross validation. Then, we trained the data using the Random Forest algorithm. But first, we are going to create a cluster to optimize our computing time.

```{r}
cluster <- makeCluster(detectCores() - 1) #Getting all the cores but one
registerDoParallel(cluster) #Registering clusters
```

Now, training the model with the above parameters, we have:


```{r modeltraining, cache=TRUE}
set.seed(20201025)
inTraining <- createDataPartition(y=WLEdataframe$classe, p = .75, list=FALSE)
training <- WLEdataframe[inTraining,]
testing <- WLEdataframe[-inTraining,]
fitControl <- trainControl(method = "cv",number = 10)
modRF <- train(training[,-49],training[,49],data=training,method="rf",
               trControl = fitControl)
modRF
```
The next chunk of code is used to close the cluster.

```{r}
stopCluster(cluster)
registerDoSEQ()
```


## Testing and Results

Now, we will test the model in the testing data and look at the confusion matrix.

```{r}
predictions <- predict(modRF, newdata=testing)
confusionMatrix(predictions, testing$classe)
```

As the accuracy is 99.63%, the Out-of-the-sample error is 1 minus the accuracy, which is 0.37%.

## The Course Project Prediction Quiz

Now, we will use our model to predict the classes for this [Testing Dataset](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv), with 20 observations.

```{r}
predictDATAFRAME <- read.csv("pml-testing.csv")
predict(modRF, newdata=predictDATAFRAME)
```


Checking this result in the quiz, we got 100% of the problems correct.